# AI-Prompt-Injection-Defense-System
This project tell us how to protect AI assistants from prompt injection attacks, a security vulnerability where users try to trick AI systems into ignoring their safety rules and revealing sensitive information.
